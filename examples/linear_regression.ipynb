{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.lax as lax\n",
    "import jax.random as jrandom\n",
    "import numpy as np\n",
    "import optax\n",
    "import distrax\n",
    "import haiku as hk\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from lfiax.flows.nsf import make_nsf\n",
    "\n",
    "from typing import (\n",
    "    Any,\n",
    "    Iterator,\n",
    "    Mapping,\n",
    "    Optional,\n",
    "    Tuple,\n",
    ")\n",
    "\n",
    "Array = jnp.ndarray\n",
    "PRNGKey = Array\n",
    "Batch = Mapping[str, np.ndarray]\n",
    "OptState = Any\n",
    "\n",
    "\n",
    "def sim_linear_jax(d: Array, priors: Array, key: PRNGKey):\n",
    "    # Keys for the appropriate functions\n",
    "    keys = jrandom.split(key, 3)\n",
    "\n",
    "    # sample random normal dist\n",
    "    noise_shape = (1,)\n",
    "\n",
    "    mu_noise = jnp.zeros(noise_shape)\n",
    "    sigma_noise = jnp.ones(noise_shape)\n",
    "\n",
    "    n_n = distrax.Independent(\n",
    "        distrax.MultivariateNormalDiag(mu_noise, sigma_noise)\n",
    "    ).sample(seed=keys[0], sample_shape=[len(d), len(priors)])\n",
    "\n",
    "    # sample random gamma noise\n",
    "    n_g = distrax.Gamma(2.0, 1.0 / 2.0).sample(\n",
    "        seed=keys[1], sample_shape=[len(d), len(priors)]\n",
    "    )\n",
    "\n",
    "    # perform forward pass\n",
    "    y = jnp.broadcast_to(priors[:, 0], (len(d), len(priors)))\n",
    "    y = y + jnp.expand_dims(d, 1) @ jnp.expand_dims(priors[:, 1], 0)\n",
    "    y = y + n_g + jnp.squeeze(n_n)\n",
    "    ygrads = priors[:, 1]\n",
    "\n",
    "    return y, ygrads\n",
    "\n",
    "\n",
    "# ----------------------------------------\n",
    "# Helper functions to simulate data\n",
    "# ----------------------------------------\n",
    "def load_dataset(split: tfds.Split, batch_size: int) -> Iterator[Batch]:\n",
    "    ds = split\n",
    "    ds = ds.shuffle(buffer_size=10 * batch_size)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(buffer_size=1000)\n",
    "    ds = ds.repeat()\n",
    "    return iter(tfds.as_numpy(ds))\n",
    "\n",
    "\n",
    "def sim_data(d: Array, priors: Array, key: PRNGKey):\n",
    "    \"\"\"\n",
    "    Returns data in a format suitable for normalizing flow training.\n",
    "    Data will be in shape [y, thetas]. The `y` variable can vary in size.\n",
    "    \"\"\"\n",
    "    keys = jrandom.split(key, 2)\n",
    "\n",
    "    theta_shape = (2,)\n",
    "\n",
    "    mu = jnp.zeros(theta_shape)\n",
    "    sigma = (3**2) * jnp.ones(theta_shape)\n",
    "\n",
    "    base_distribution = distrax.Independent(  # Should this be independent?\n",
    "        distrax.MultivariateNormalDiag(mu, sigma)\n",
    "    )\n",
    "\n",
    "    priors = base_distribution.sample(seed=keys[0], sample_shape=[num_samples])\n",
    "\n",
    "    # ygrads allows to be compared to other implementations (Kleinegesse et)\n",
    "    y, ygrads = sim_linear_jax(d, priors, keys[1])\n",
    "\n",
    "    return jnp.column_stack((y.T, jnp.squeeze(priors), jnp.broadcast_to(d, (num_samples, len(d)))))\n",
    "\n",
    "\n",
    "def prepare_data(batch: Batch, prng_key: Optional[PRNGKey] = None) -> Array:\n",
    "    # Batch is [y, thetas, d]\n",
    "    data = batch.astype(np.float32)\n",
    "    # Handling the scalar case\n",
    "    if data.shape[1] <= 3:\n",
    "        x = jnp.expand_dims(data[:, :-2], -1)\n",
    "    # Use known length of x to split up the cond_data\n",
    "    # data_shape = data.shape\n",
    "    # start = [0, 0]\n",
    "    # stop = [data_shape[0], len_x]\n",
    "    # y = lax.dynamic_slice(data, start, stop)\n",
    "    x = data[:, :len_x]\n",
    "    cond_data = data[:, len_x:]\n",
    "    theta = cond_data[:, :-len_x]\n",
    "    d = cond_data[:, -len_x:-len_xi]\n",
    "    xi = cond_data[:, -len_xi:]\n",
    "    # return x, cond_data\n",
    "    # breakpoint()\n",
    "    # return y, theta, x, xi\n",
    "    return x, theta, d, xi\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Haiku transform functions for training and evaluation\n",
    "# ----------------------------\n",
    "@hk.without_apply_rng\n",
    "@hk.transform\n",
    "def log_prob(data: Array, theta: Array, d: Array, xi: Array) -> Array:\n",
    "    # Get batch\n",
    "    shift = data.mean(axis=0)\n",
    "    scale = data.std(axis=0) + 1e-14\n",
    "    \n",
    "    model = make_nsf(\n",
    "        event_shape=EVENT_SHAPE,\n",
    "        cond_info_shape=cond_info_shape,\n",
    "        num_layers=flow_num_layers,\n",
    "        hidden_sizes=[hidden_size] * mlp_num_layers,\n",
    "        num_bins=num_bins,\n",
    "        standardize_x=True,\n",
    "        standardize_theta=False,\n",
    "        use_resnet=True,\n",
    "        event_dim=EVENT_DIM,\n",
    "        shift=shift,\n",
    "        scale=scale,\n",
    "    )\n",
    "    return model.log_prob(data, theta, d, xi)\n",
    "\n",
    "\n",
    "@hk.without_apply_rng\n",
    "@hk.transform\n",
    "def model_sample(key: PRNGKey, num_samples: int, cond_data: Array) -> Array:\n",
    "    # TODO: update this method?\n",
    "    model = make_nsf(\n",
    "        event_shape=EVENT_SHAPE,\n",
    "        cond_info_shape=cond_info_shape,\n",
    "        num_layers=flow_num_layers,\n",
    "        hidden_sizes=[hidden_size] * mlp_num_layers,\n",
    "        num_bins=num_bins,\n",
    "    )\n",
    "    z = jnp.repeat(cond_data, num_samples, axis=0)\n",
    "    z = jnp.expand_dims(z, -1)\n",
    "    return model._sample_n(key=key, n=[num_samples], z=z)\n",
    "\n",
    "\n",
    "def loss_fn(params: hk.Params, prng_key: PRNGKey, x: Array, theta: Array, d: Array, xi: Array) -> Array:\n",
    "    # x, cond_data = prepare_data(batch, prng_key)\n",
    "    # I wonder if this will work...\n",
    "    # cond_data = jnp.concatenate((theta, d, xi), axis=1)\n",
    "    # Loss is average negative log likelihood.\n",
    "    loss = -jnp.mean(log_prob.apply(params, x, theta, d, xi))\n",
    "    # loss = -jnp.mean(log_prob.apply(params, x, cond_data))\n",
    "    return loss\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def eval_fn(params: hk.Params, batch: Batch) -> Array:\n",
    "    x, theta, d, xi = prepare_data(batch)\n",
    "    # cond_data = jnp.concatenate((theta, d, xi), axis=1)\n",
    "    loss = -jnp.mean(log_prob.apply(params, x, theta, d, xi))\n",
    "    # loss = -jnp.mean(log_prob.apply(params, x, cond_data))\n",
    "    return loss\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def update(\n",
    "    params: hk.Params, prng_key: PRNGKey, opt_state: OptState, batch: Batch\n",
    ") -> Tuple[hk.Params, OptState]:\n",
    "    \"\"\"Single SGD update step.\"\"\"\n",
    "    # x, cond_data = prepare_data(batch, prng_key)\n",
    "    x, theta, d, xi = prepare_data(batch)\n",
    "    grads = jax.grad(loss_fn)(params, prng_key, x, theta, d, xi)\n",
    "    grads_d = jax.grad(loss_fn, argnums=5)(params, prng_key, x, theta, d, xi)\n",
    "    updates, new_opt_state = optimizer.update(grads, opt_state)\n",
    "    new_params = optax.apply_updates(params, updates)\n",
    "    return new_params, new_opt_state, grads_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "key = jrandom.PRNGKey(seed)\n",
    "d_prop = jrandom.uniform(key, shape=(1,), minval=-10., maxval=10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_obs = jnp.array([1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.concatenate((d_obs, d_prop), axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 55\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39m# Training\u001b[39;00m\n\u001b[1;32m     54\u001b[0m prng_seq \u001b[39m=\u001b[39m hk\u001b[39m.\u001b[39mPRNGSequence(\u001b[39m42\u001b[39m)\n\u001b[0;32m---> 55\u001b[0m params \u001b[39m=\u001b[39m log_prob\u001b[39m.\u001b[39;49minit(\n\u001b[1;32m     56\u001b[0m     \u001b[39mnext\u001b[39;49m(prng_seq),\n\u001b[1;32m     57\u001b[0m     np\u001b[39m.\u001b[39;49mzeros((\u001b[39m1\u001b[39;49m, \u001b[39m*\u001b[39;49mEVENT_SHAPE)),\n\u001b[1;32m     58\u001b[0m     np\u001b[39m.\u001b[39;49mzeros((\u001b[39m1\u001b[39;49m, \u001b[39m*\u001b[39;49mtheta_shape)),\n\u001b[1;32m     59\u001b[0m     np\u001b[39m.\u001b[39;49mzeros((\u001b[39m1\u001b[39;49m, \u001b[39m*\u001b[39;49md_shape)),\n\u001b[1;32m     60\u001b[0m     np\u001b[39m.\u001b[39;49mzeros((\u001b[39m1\u001b[39;49m, \u001b[39m*\u001b[39;49mxi_shape)),\n\u001b[1;32m     61\u001b[0m )\n\u001b[1;32m     62\u001b[0m \u001b[39m# log_prob.init(next(prng_seq), np.zeros((1, *EVENT_SHAPE)), np.zeros((1, *theta_shape)), np.zeros((1, *d_shape)), np.zeros((1, *xi_shape)),)\u001b[39;00m\n\u001b[1;32m     63\u001b[0m opt_state \u001b[39m=\u001b[39m optimizer\u001b[39m.\u001b[39minit(params)\n",
      "File \u001b[0;32m~/anaconda3/envs/sdm3/lib/python3.9/site-packages/haiku/_src/transform.py:114\u001b[0m, in \u001b[0;36mwithout_state.<locals>.init_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minit_fn\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 114\u001b[0m   params, state \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39;49minit(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    115\u001b[0m   \u001b[39mif\u001b[39;00m state:\n\u001b[1;32m    116\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIf your transformed function uses `hk.\u001b[39m\u001b[39m{\u001b[39m\u001b[39mget,set}_state` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    117\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mthen use `hk.transform_with_state`.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/sdm3/lib/python3.9/site-packages/haiku/_src/transform.py:338\u001b[0m, in \u001b[0;36mtransform_with_state.<locals>.init_fn\u001b[0;34m(rng, *args, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[39mwith\u001b[39;00m base\u001b[39m.\u001b[39mnew_context(rng\u001b[39m=\u001b[39mrng) \u001b[39mas\u001b[39;00m ctx:\n\u001b[1;32m    337\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 338\u001b[0m     f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    339\u001b[0m   \u001b[39mexcept\u001b[39;00m jax\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mUnexpectedTracerError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    340\u001b[0m     \u001b[39mraise\u001b[39;00m jax\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mUnexpectedTracerError(unexpected_tracer_hint) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [1], line 138\u001b[0m, in \u001b[0;36mlog_prob\u001b[0;34m(data, theta, d, xi)\u001b[0m\n\u001b[1;32m    123\u001b[0m scale \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mstd(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m1e-14\u001b[39m\n\u001b[1;32m    125\u001b[0m model \u001b[39m=\u001b[39m make_nsf(\n\u001b[1;32m    126\u001b[0m     event_shape\u001b[39m=\u001b[39mEVENT_SHAPE,\n\u001b[1;32m    127\u001b[0m     cond_info_shape\u001b[39m=\u001b[39mcond_info_shape,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     scale\u001b[39m=\u001b[39mscale,\n\u001b[1;32m    137\u001b[0m )\n\u001b[0;32m--> 138\u001b[0m \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39;49mlog_prob(data, theta, d, xi)\n",
      "File \u001b[0;32m~/Development/lfiax/src/lfiax/distributions/transformed_conditional.py:32\u001b[0m, in \u001b[0;36mlog_prob\u001b[0;34m(self, value, theta, d, xi)\u001b[0m\n\u001b[1;32m     29\u001b[0m     y, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbijector\u001b[39m.\u001b[39mforward_and_log_det(x, theta, d, xi)\n\u001b[1;32m     30\u001b[0m     \u001b[39mreturn\u001b[39;00m y\n\u001b[0;32m---> 32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog_prob\u001b[39m(\u001b[39mself\u001b[39m, value: Array, theta: Array, d: Array, xi: Array) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Array:\n\u001b[1;32m     33\u001b[0m     \u001b[39m\"\"\"See `Distribution.log_prob`.\"\"\"\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     x, ildj_y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbijector\u001b[39m.\u001b[39minverse_and_log_det(value, theta, d, xi)\n",
      "File \u001b[0;32m~/Development/lfiax/src/lfiax/bijectors/inverse_conditional.py:31\u001b[0m, in \u001b[0;36minverse_and_log_det\u001b[0;34m(self, y, theta, d, xi)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[39m\"\"\"Computes y = f(x|z) and log|det J(f)(x|z)|.\"\"\"\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bijector\u001b[39m.\u001b[39minverse_and_log_det(x, theta, d, xi)\n\u001b[0;32m---> 31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minverse_and_log_det\u001b[39m(\n\u001b[1;32m     32\u001b[0m     \u001b[39mself\u001b[39m, y: Array, theta: Array, d: Array, xi: Array\n\u001b[1;32m     33\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Array, Array]:\n\u001b[1;32m     34\u001b[0m     \u001b[39m\"\"\"Computes x = f^{-1}(y) and log|det J(f^{-1})(y)|.\"\"\"\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bijector\u001b[39m.\u001b[39mforward_and_log_det(y, theta, d, xi)\n",
      "File \u001b[0;32m~/Development/lfiax/src/lfiax/bijectors/chain_conditional.py:31\u001b[0m, in \u001b[0;36mConditionalChain.forward_and_log_det\u001b[0;34m(self, x, theta, d, xi)\u001b[0m\n\u001b[1;32m     26\u001b[0m         y \u001b[39m=\u001b[39m bijector\u001b[39m.\u001b[39minverse(y, theta, d, xi)\n\u001b[1;32m     27\u001b[0m     \u001b[39mreturn\u001b[39;00m y\n\u001b[1;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward_and_log_det\u001b[39m(\n\u001b[1;32m     30\u001b[0m     \u001b[39mself\u001b[39m, x: Array, theta: Array, d: Array, xi: Array\n\u001b[0;32m---> 31\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Array, Array]:\n\u001b[1;32m     32\u001b[0m     \u001b[39m\"\"\"Computes y = f(x|z) and log|det J(f)(x|z)|.\"\"\"\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     x, log_det \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bijectors[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mforward_and_log_det(x, theta, d, xi)\n",
      "File \u001b[0;32m~/Development/lfiax/src/lfiax/bijectors/masked_coupling_conditional.py:45\u001b[0m, in \u001b[0;36mMaskedConditionalCoupling.forward_and_log_det\u001b[0;34m(self, x, theta, d, xi)\u001b[0m\n\u001b[1;32m     43\u001b[0m self._check_forward_input_shape(x)\n\u001b[1;32m     44\u001b[0m masked_x = jnp.where(self._event_mask, x, 0.0)\n\u001b[0;32m---> 45\u001b[0m # TODO: Better logic to detect when scalar x\n\u001b[1;32m     46\u001b[0m if masked_x.shape[1] == 1:\n\u001b[1;32m     47\u001b[0m     params = self._conditioner(theta, d, xi)\n",
      "File \u001b[0;32m~/anaconda3/envs/sdm3/lib/python3.9/site-packages/haiku/_src/module.py:434\u001b[0m, in \u001b[0;36mwrap_method.<locals>.wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m     local_module_name \u001b[39m=\u001b[39m module_name\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    432\u001b[0m     f \u001b[39m=\u001b[39m stateful\u001b[39m.\u001b[39mnamed_call(f, name\u001b[39m=\u001b[39mlocal_module_name)\n\u001b[0;32m--> 434\u001b[0m out \u001b[39m=\u001b[39m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    436\u001b[0m \u001b[39m# Module names are set in the constructor. If `f` is the constructor then\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[39m# its name will only be set **after** `f` has run. For methods other\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[39m# than `__init__` we need the name before running in order to wrap their\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \u001b[39m# execution with `named_call`.\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \u001b[39mif\u001b[39;00m module_name \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/sdm3/lib/python3.9/contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[1;32m     78\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 79\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/anaconda3/envs/sdm3/lib/python3.9/site-packages/haiku/_src/module.py:273\u001b[0m, in \u001b[0;36mrun_interceptors\u001b[0;34m(bound_method, method_name, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[39m\"\"\"Runs any method interceptors or the original method.\"\"\"\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m interceptor_stack:\n\u001b[0;32m--> 273\u001b[0m   \u001b[39mreturn\u001b[39;00m bound_method(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    275\u001b[0m ctx \u001b[39m=\u001b[39m MethodContext(module\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m,\n\u001b[1;32m    276\u001b[0m                     method_name\u001b[39m=\u001b[39mmethod_name,\n\u001b[1;32m    277\u001b[0m                     orig_method\u001b[39m=\u001b[39mbound_method)\n\u001b[1;32m    278\u001b[0m interceptor_stack_copy \u001b[39m=\u001b[39m interceptor_stack\u001b[39m.\u001b[39mclone()\n",
      "File \u001b[0;32m~/Development/lfiax/src/lfiax/nets/scalar_conditioners.py:31\u001b[0m, in \u001b[0;36mscalar_conditioner_mlp.<locals>.ConditionerModule.__call__\u001b[0;34m(self, theta, d, xi)\u001b[0m\n\u001b[1;32m     29\u001b[0m xi \u001b[39m=\u001b[39m hk\u001b[39m.\u001b[39mFlatten()(xi)\n\u001b[1;32m     30\u001b[0m \u001b[39m# Will this give me the same problem as before i.e. nans?\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m z \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39;49mconcatenate((theta, d, xi), axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     32\u001b[0m \u001b[39mif\u001b[39;00m resnet:\n\u001b[1;32m     33\u001b[0m     \u001b[39mfor\u001b[39;00m hidden \u001b[39min\u001b[39;00m hidden_sizes:\n",
      "File \u001b[0;32m~/anaconda3/envs/sdm3/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py:1683\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(arrays, axis, dtype)\u001b[0m\n\u001b[1;32m   1681\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(arrays[\u001b[39m0\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mconcatenate\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m   1682\u001b[0m   \u001b[39mreturn\u001b[39;00m arrays[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mconcatenate(arrays[\u001b[39m1\u001b[39m:], axis, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m-> 1683\u001b[0m axis \u001b[39m=\u001b[39m _canonicalize_axis(axis, ndim(arrays[\u001b[39m0\u001b[39;49m]))\n\u001b[1;32m   1684\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1685\u001b[0m   arrays \u001b[39m=\u001b[39m _promote_dtypes(\u001b[39m*\u001b[39marrays)\n",
      "File \u001b[0;32m~/anaconda3/envs/sdm3/lib/python3.9/site-packages/jax/_src/util.py:394\u001b[0m, in \u001b[0;36mcanonicalize_axis\u001b[0;34m(axis, num_dims)\u001b[0m\n\u001b[1;32m    392\u001b[0m axis \u001b[39m=\u001b[39m operator\u001b[39m.\u001b[39mindex(axis)\n\u001b[1;32m    393\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m-\u001b[39mnum_dims \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m axis \u001b[39m<\u001b[39m num_dims:\n\u001b[0;32m--> 394\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39maxis \u001b[39m\u001b[39m{\u001b[39;00maxis\u001b[39m}\u001b[39;00m\u001b[39m is out of bounds for array of dimension \u001b[39m\u001b[39m{\u001b[39;00mnum_dims\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    395\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    396\u001b[0m   axis \u001b[39m=\u001b[39m axis \u001b[39m+\u001b[39m num_dims\n",
      "\u001b[0;31mValueError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "# TODO: Put this in hydra config file\n",
    "seed = 1231\n",
    "key = jrandom.PRNGKey(seed)\n",
    "\n",
    "# d = jnp.array([-10.0, 0.0, 5.0, 10.0])\n",
    "# d = jnp.array([1., 2.])\n",
    "# d = jnp.array([1.])\n",
    "d_obs = jnp.array([])\n",
    "d_prop = jrandom.uniform(key, shape=(1,), minval=-10., maxval=10.)\n",
    "d_sim = jnp.concatenate((d_obs, d_prop), axis=0)\n",
    "len_x = len(d_sim)\n",
    "len_d = len(d_obs)\n",
    "len_xi = len(d_prop)\n",
    "num_samples = 100\n",
    "\n",
    "# Params and hyperparams\n",
    "theta_shape = (2,)\n",
    "d_shape = (len(d_obs),)\n",
    "xi_shape = (len_xi, )\n",
    "EVENT_SHAPE = (len(d_sim),)\n",
    "# EVENT_DIM is important for the normalizing flow's block.\n",
    "EVENT_DIM = 1\n",
    "cond_info_shape = (theta_shape[0], len_d, len_xi)\n",
    "\n",
    "batch_size = 128\n",
    "flow_num_layers = 10\n",
    "mlp_num_layers = 4\n",
    "hidden_size = 500\n",
    "num_bins = 4\n",
    "learning_rate = 1e-4\n",
    "\n",
    "training_steps = 10  # 00\n",
    "eval_frequency = 100\n",
    "\n",
    "optimizer = optax.adam(learning_rate)\n",
    "\n",
    "# Simulating the data to be used to train the flow.\n",
    "num_samples = 10000\n",
    "# TODO: put this function in training since d will be changing.\n",
    "X = sim_data(d_sim, num_samples, key)\n",
    "\n",
    "# Create tf dataset from sklearn dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X)\n",
    "\n",
    "# Splitting into train/validate ds\n",
    "train = dataset.skip(2000)\n",
    "val = dataset.take(2000)\n",
    "\n",
    "# load_dataset(split: tfds.Split, batch_size: int)\n",
    "train_ds = load_dataset(train, 512)\n",
    "valid_ds = load_dataset(val, 512)\n",
    "\n",
    "# Training\n",
    "prng_seq = hk.PRNGSequence(42)\n",
    "params = log_prob.init(\n",
    "    next(prng_seq),\n",
    "    np.zeros((1, *EVENT_SHAPE)),\n",
    "    np.zeros((1, *theta_shape)),\n",
    "    np.zeros((1, *d_shape)),\n",
    "    np.zeros((1, *xi_shape)),\n",
    ")\n",
    "# log_prob.init(next(prng_seq), np.zeros((1, *EVENT_SHAPE)), np.zeros((1, *theta_shape)), np.zeros((1, *d_shape)), np.zeros((1, *xi_shape)),)\n",
    "opt_state = optimizer.init(params)\n",
    "\n",
    "for step in range(training_steps):\n",
    "    params, opt_state, grads_d = update(params, next(prng_seq), opt_state, next(train_ds))\n",
    "\n",
    "    if step % eval_frequency == 0:\n",
    "        val_loss = eval_fn(params, next(valid_ds))\n",
    "        print(f\"STEP: {step:5d}; Validation loss: {val_loss:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[ 8.58054136e-06],\n",
       "             [ 4.45904625e-05],\n",
       "             [-6.64754625e-05],\n",
       "             [ 1.46706216e-05],\n",
       "             [ 2.52232876e-05],\n",
       "             [ 2.49716686e-05],\n",
       "             [ 2.80937675e-05],\n",
       "             [-4.05143765e-05],\n",
       "             [ 7.35401682e-06],\n",
       "             [-2.07667599e-05],\n",
       "             [-1.03341454e-05],\n",
       "             [ 1.38780279e-05],\n",
       "             [ 3.43079228e-05],\n",
       "             [ 2.87153671e-05],\n",
       "             [-6.39944483e-05],\n",
       "             [-1.82727035e-05],\n",
       "             [ 2.69337761e-05],\n",
       "             [ 5.48985327e-06],\n",
       "             [ 6.74346011e-05],\n",
       "             [ 6.72573969e-06],\n",
       "             [-2.78310108e-05],\n",
       "             [-2.43198065e-06],\n",
       "             [ 2.24746400e-05],\n",
       "             [ 3.94023045e-05],\n",
       "             [-2.85463539e-05],\n",
       "             [ 2.49182176e-05],\n",
       "             [ 1.65218000e-06],\n",
       "             [-5.70363773e-06],\n",
       "             [-7.80298942e-05],\n",
       "             [ 1.21026869e-05],\n",
       "             [ 1.05954987e-05],\n",
       "             [ 2.10282269e-05],\n",
       "             [ 3.70298330e-05],\n",
       "             [ 5.37535243e-07],\n",
       "             [ 3.12398006e-05],\n",
       "             [ 2.29002831e-06],\n",
       "             [ 6.99698603e-07],\n",
       "             [ 1.04659739e-05],\n",
       "             [-5.42306043e-06],\n",
       "             [ 4.12623085e-05],\n",
       "             [ 1.20321056e-05],\n",
       "             [ 4.61302625e-05],\n",
       "             [ 4.08085725e-05],\n",
       "             [ 2.80812455e-05],\n",
       "             [ 4.85842565e-06],\n",
       "             [-7.78273679e-05],\n",
       "             [ 3.65746600e-05],\n",
       "             [ 1.80554052e-05],\n",
       "             [ 1.20944023e-05],\n",
       "             [-1.23609789e-04],\n",
       "             [-9.07242429e-06],\n",
       "             [-5.10188283e-06],\n",
       "             [ 8.82444510e-06],\n",
       "             [ 7.16805807e-05],\n",
       "             [-2.31228523e-06],\n",
       "             [ 2.63511447e-05],\n",
       "             [-7.15236638e-06],\n",
       "             [-3.89000168e-04],\n",
       "             [ 3.49439688e-06],\n",
       "             [ 2.84857560e-05],\n",
       "             [-3.79119865e-06],\n",
       "             [-2.13360022e-06],\n",
       "             [ 3.43498323e-05],\n",
       "             [ 2.08072379e-05],\n",
       "             [ 5.87067370e-06],\n",
       "             [-7.56294457e-06],\n",
       "             [-1.04024991e-07],\n",
       "             [ 3.35693658e-05],\n",
       "             [ 1.66621048e-05],\n",
       "             [-3.59627597e-06],\n",
       "             [ 1.24867929e-05],\n",
       "             [ 1.15172070e-05],\n",
       "             [ 4.71696922e-06],\n",
       "             [ 1.10732304e-04],\n",
       "             [ 5.38332351e-05],\n",
       "             [-8.79599065e-06],\n",
       "             [ 3.95568968e-05],\n",
       "             [ 4.02187561e-06],\n",
       "             [ 1.61033822e-05],\n",
       "             [-1.97596280e-04],\n",
       "             [-1.93412925e-05],\n",
       "             [-6.53662391e-06],\n",
       "             [ 1.90436003e-05],\n",
       "             [ 3.30450130e-05],\n",
       "             [ 3.59851538e-06],\n",
       "             [-3.97434678e-06],\n",
       "             [ 1.29332357e-05],\n",
       "             [ 1.05833788e-05],\n",
       "             [ 2.69702177e-05],\n",
       "             [-1.68292232e-07],\n",
       "             [-1.81038854e-06],\n",
       "             [ 6.94972914e-06],\n",
       "             [ 1.07694893e-06],\n",
       "             [-6.10230836e-06],\n",
       "             [ 1.32587174e-05],\n",
       "             [ 3.60049557e-06],\n",
       "             [-2.40125610e-05],\n",
       "             [ 1.75849436e-05],\n",
       "             [ 3.84500017e-05],\n",
       "             [-1.10598448e-05],\n",
       "             [ 2.84307989e-05],\n",
       "             [-8.61010449e-06],\n",
       "             [-5.50226978e-05],\n",
       "             [-1.53910805e-05],\n",
       "             [-1.15320981e-05],\n",
       "             [ 1.38390542e-05],\n",
       "             [-5.38104578e-05],\n",
       "             [ 1.32480309e-05],\n",
       "             [ 2.84645430e-05],\n",
       "             [ 8.58012845e-06],\n",
       "             [ 2.76255719e-06],\n",
       "             [ 3.97468148e-06],\n",
       "             [ 1.21287867e-05],\n",
       "             [ 3.32484819e-06],\n",
       "             [-6.04703928e-06],\n",
       "             [ 2.92447330e-05],\n",
       "             [ 4.19763237e-05],\n",
       "             [-1.66366317e-05],\n",
       "             [ 2.22845265e-05],\n",
       "             [ 2.32916063e-05],\n",
       "             [ 2.59866283e-06],\n",
       "             [ 8.32502064e-06],\n",
       "             [ 3.36536687e-05],\n",
       "             [-2.07367775e-05],\n",
       "             [ 9.42026418e-06],\n",
       "             [ 2.56398812e-06],\n",
       "             [ 1.52867833e-05],\n",
       "             [-1.36791614e-05],\n",
       "             [-1.10005494e-05],\n",
       "             [ 1.69742222e-07],\n",
       "             [ 2.44083167e-05],\n",
       "             [-1.08446475e-05],\n",
       "             [-7.17195326e-06],\n",
       "             [-2.14643824e-05],\n",
       "             [-2.06841723e-05],\n",
       "             [ 3.27697999e-05],\n",
       "             [-9.07205413e-06],\n",
       "             [ 5.73899979e-06],\n",
       "             [-3.15989237e-05],\n",
       "             [ 2.06016057e-06],\n",
       "             [ 4.31567287e-06],\n",
       "             [ 6.71297312e-06],\n",
       "             [ 5.46311412e-06],\n",
       "             [ 4.58228278e-05],\n",
       "             [-8.44233546e-06],\n",
       "             [-1.58185256e-04],\n",
       "             [ 1.39002179e-06],\n",
       "             [ 3.55151712e-08],\n",
       "             [ 1.66808568e-05],\n",
       "             [ 5.77416813e-06],\n",
       "             [ 5.66725987e-07],\n",
       "             [ 6.44318243e-06],\n",
       "             [ 1.62301410e-06],\n",
       "             [-1.22624897e-05],\n",
       "             [-6.56856912e-07],\n",
       "             [ 4.98182962e-05],\n",
       "             [ 2.23052848e-05],\n",
       "             [ 2.96838716e-05],\n",
       "             [ 1.06637908e-05],\n",
       "             [ 4.38879880e-07],\n",
       "             [ 4.73517648e-05],\n",
       "             [ 2.11265906e-05],\n",
       "             [-4.39567521e-04],\n",
       "             [ 2.98907162e-05],\n",
       "             [ 5.80184951e-06],\n",
       "             [-1.50249002e-06],\n",
       "             [ 9.46831096e-06],\n",
       "             [-1.51679524e-05],\n",
       "             [ 1.21212861e-05],\n",
       "             [-9.11584539e-06],\n",
       "             [-1.82142412e-06],\n",
       "             [ 2.49028872e-05],\n",
       "             [-2.45846495e-05],\n",
       "             [ 2.79894684e-05],\n",
       "             [-9.82177335e-06],\n",
       "             [-8.85224108e-06],\n",
       "             [-9.53346898e-06],\n",
       "             [-4.45134719e-06],\n",
       "             [-5.53278733e-05],\n",
       "             [ 3.75665659e-05],\n",
       "             [ 3.22718233e-06],\n",
       "             [ 2.29171455e-05],\n",
       "             [ 1.00006682e-05],\n",
       "             [ 1.42101126e-05],\n",
       "             [ 1.25296574e-05],\n",
       "             [-9.79639117e-06],\n",
       "             [-1.62499055e-06],\n",
       "             [ 1.90500978e-05],\n",
       "             [ 5.32874537e-06],\n",
       "             [-6.89890148e-05],\n",
       "             [-8.90551291e-06],\n",
       "             [ 5.51781841e-06],\n",
       "             [-2.73387777e-05],\n",
       "             [-5.61430134e-05],\n",
       "             [-7.01791123e-06],\n",
       "             [ 3.48780231e-05],\n",
       "             [ 2.34942104e-06],\n",
       "             [-9.32334588e-05],\n",
       "             [ 1.55212056e-05],\n",
       "             [ 6.48285277e-05],\n",
       "             [ 2.21072833e-06],\n",
       "             [ 7.79488801e-07],\n",
       "             [-4.07327097e-05],\n",
       "             [ 2.55660198e-05],\n",
       "             [-3.72305549e-05],\n",
       "             [-3.60731042e-06],\n",
       "             [ 2.57254760e-05],\n",
       "             [ 1.98370071e-05],\n",
       "             [ 2.12530676e-06],\n",
       "             [-3.91698923e-05],\n",
       "             [ 6.04812840e-06],\n",
       "             [ 5.60491435e-06],\n",
       "             [ 2.02068932e-05],\n",
       "             [-2.79810320e-06],\n",
       "             [ 1.72724576e-05],\n",
       "             [ 4.20898868e-05],\n",
       "             [-1.20407112e-05],\n",
       "             [-2.59772714e-05],\n",
       "             [-1.24912222e-05],\n",
       "             [ 1.26316791e-05],\n",
       "             [ 1.64812191e-05],\n",
       "             [-5.43579017e-06],\n",
       "             [ 7.48490947e-06],\n",
       "             [ 8.67626295e-06],\n",
       "             [-1.49224243e-05],\n",
       "             [ 9.74917748e-06],\n",
       "             [ 1.54084482e-05],\n",
       "             [ 7.25895879e-05],\n",
       "             [ 1.15454486e-06],\n",
       "             [ 3.47534369e-05],\n",
       "             [-1.79828894e-05],\n",
       "             [ 2.12107061e-05],\n",
       "             [-1.78785303e-05],\n",
       "             [ 6.90236675e-06],\n",
       "             [ 1.33257545e-05],\n",
       "             [ 3.02084300e-06],\n",
       "             [ 2.15118926e-05],\n",
       "             [ 1.21064586e-05],\n",
       "             [ 5.65633536e-06],\n",
       "             [ 3.33776479e-05],\n",
       "             [ 3.58961461e-06],\n",
       "             [ 3.89262059e-05],\n",
       "             [ 4.25865437e-05],\n",
       "             [ 4.38329917e-05],\n",
       "             [ 1.44645946e-05],\n",
       "             [ 2.66495772e-05],\n",
       "             [-3.59395963e-05],\n",
       "             [-1.14278182e-05],\n",
       "             [-6.51132541e-06],\n",
       "             [ 3.86909232e-05],\n",
       "             [-5.84642294e-06],\n",
       "             [ 1.25712522e-05],\n",
       "             [ 1.60181062e-05],\n",
       "             [-4.22223366e-06],\n",
       "             [-1.19283072e-09],\n",
       "             [-1.23458449e-05],\n",
       "             [ 2.20616475e-05],\n",
       "             [ 5.09291931e-05],\n",
       "             [-7.40900350e-06],\n",
       "             [-1.02023787e-05],\n",
       "             [ 1.27947051e-05],\n",
       "             [-1.41239711e-04],\n",
       "             [ 1.12711095e-05],\n",
       "             [ 1.38957857e-05],\n",
       "             [-4.86393719e-06],\n",
       "             [ 7.69431572e-05],\n",
       "             [ 4.05608444e-05],\n",
       "             [ 9.59417048e-06],\n",
       "             [-6.84196175e-06],\n",
       "             [ 2.66538027e-05],\n",
       "             [ 1.23372683e-05],\n",
       "             [ 7.07705840e-06],\n",
       "             [-1.64628023e-06],\n",
       "             [ 6.41717997e-05],\n",
       "             [ 1.88912109e-05],\n",
       "             [-4.34233243e-07],\n",
       "             [ 2.82787314e-05],\n",
       "             [ 1.56413316e-05],\n",
       "             [ 7.72832791e-05],\n",
       "             [-3.65332721e-06],\n",
       "             [ 8.16487227e-06],\n",
       "             [-2.90061007e-06],\n",
       "             [ 1.83124848e-05],\n",
       "             [ 1.68895749e-05],\n",
       "             [ 1.58070725e-05],\n",
       "             [ 2.53527887e-05],\n",
       "             [ 5.42325324e-06],\n",
       "             [ 1.33612311e-05],\n",
       "             [ 1.15737976e-06],\n",
       "             [-4.74206281e-05],\n",
       "             [ 2.31429549e-05],\n",
       "             [-1.06366599e-04],\n",
       "             [ 1.16535966e-06],\n",
       "             [ 2.61728565e-05],\n",
       "             [ 9.25350469e-06],\n",
       "             [ 1.43655416e-05],\n",
       "             [-3.11018630e-05],\n",
       "             [ 1.07644755e-05],\n",
       "             [ 6.80140147e-06],\n",
       "             [ 1.63230379e-05],\n",
       "             [ 1.08192835e-05],\n",
       "             [ 1.79677409e-05],\n",
       "             [-7.89038040e-06],\n",
       "             [-1.07466594e-05],\n",
       "             [ 4.66627935e-05],\n",
       "             [ 8.04812043e-06],\n",
       "             [ 8.16149350e-06],\n",
       "             [-4.24982063e-05],\n",
       "             [-1.11948702e-05],\n",
       "             [ 1.85427070e-05],\n",
       "             [ 4.01485195e-05],\n",
       "             [-3.25427862e-07],\n",
       "             [ 1.25272372e-05],\n",
       "             [-2.23439129e-05],\n",
       "             [ 6.43965177e-05],\n",
       "             [-8.30036879e-06],\n",
       "             [-2.10973703e-05],\n",
       "             [-3.81155292e-06],\n",
       "             [ 6.10645338e-06],\n",
       "             [ 7.51513580e-05],\n",
       "             [-1.01120950e-05],\n",
       "             [ 3.07082228e-05],\n",
       "             [ 2.36927754e-05],\n",
       "             [-5.83916062e-06],\n",
       "             [-5.70443626e-06],\n",
       "             [ 2.32110888e-05],\n",
       "             [ 1.34264037e-05],\n",
       "             [ 2.01878447e-05],\n",
       "             [ 2.86539180e-05],\n",
       "             [ 6.62823004e-05],\n",
       "             [-6.68001012e-05],\n",
       "             [-8.36765139e-06],\n",
       "             [-2.40057670e-05],\n",
       "             [ 2.40613917e-05],\n",
       "             [ 3.23704880e-05],\n",
       "             [-6.90233992e-06],\n",
       "             [ 4.87336365e-05],\n",
       "             [-1.20468903e-05],\n",
       "             [-1.12704947e-05],\n",
       "             [ 3.60928752e-05],\n",
       "             [ 1.75262448e-05],\n",
       "             [-6.86954081e-06],\n",
       "             [ 4.80085691e-06],\n",
       "             [-1.21501562e-05],\n",
       "             [ 1.54239151e-05],\n",
       "             [-1.31569841e-05],\n",
       "             [-1.28516531e-05],\n",
       "             [ 2.22055587e-05],\n",
       "             [ 4.11746078e-05],\n",
       "             [-1.16150331e-04],\n",
       "             [ 9.05634079e-06],\n",
       "             [ 1.07789356e-05],\n",
       "             [ 3.89870584e-05],\n",
       "             [ 7.71390933e-06],\n",
       "             [-2.20094830e-06],\n",
       "             [-3.66539607e-05],\n",
       "             [ 3.47950081e-05],\n",
       "             [-2.41817514e-04],\n",
       "             [-1.33333615e-05],\n",
       "             [ 6.21516592e-05],\n",
       "             [ 3.34382130e-05],\n",
       "             [ 1.08417798e-05],\n",
       "             [ 2.01902913e-05],\n",
       "             [ 2.71894169e-05],\n",
       "             [ 6.35367905e-05],\n",
       "             [ 7.01241606e-06],\n",
       "             [ 5.44988279e-06],\n",
       "             [ 1.43275147e-05],\n",
       "             [ 6.15426834e-05],\n",
       "             [-5.48681382e-05],\n",
       "             [ 3.82556027e-05],\n",
       "             [-1.02552008e-06],\n",
       "             [-2.69646735e-05],\n",
       "             [ 5.99385930e-06],\n",
       "             [ 1.05837380e-05],\n",
       "             [-6.29648184e-06],\n",
       "             [ 4.30886867e-05],\n",
       "             [ 1.50110609e-05],\n",
       "             [ 9.70532128e-05],\n",
       "             [ 8.92245771e-06],\n",
       "             [ 5.58560969e-05],\n",
       "             [-6.38486108e-06],\n",
       "             [ 1.30512408e-05],\n",
       "             [-3.70229623e-06],\n",
       "             [ 3.78520999e-05],\n",
       "             [-1.03999901e-05],\n",
       "             [-3.59025202e-04],\n",
       "             [-5.21113907e-06],\n",
       "             [ 3.21808875e-06],\n",
       "             [-3.30323041e-06],\n",
       "             [ 1.63436107e-06],\n",
       "             [ 2.86536088e-05],\n",
       "             [ 2.78050948e-06],\n",
       "             [ 9.85237875e-06],\n",
       "             [ 8.30076317e-07],\n",
       "             [ 1.11109102e-06],\n",
       "             [ 8.98590588e-06],\n",
       "             [-2.38858847e-05],\n",
       "             [ 5.25397481e-05],\n",
       "             [ 1.10614619e-05],\n",
       "             [ 1.26884279e-05],\n",
       "             [ 2.91119286e-05],\n",
       "             [-1.93641790e-06],\n",
       "             [ 7.43020382e-06],\n",
       "             [ 1.56982824e-05],\n",
       "             [ 5.03987758e-05],\n",
       "             [ 4.67211721e-05],\n",
       "             [ 3.76405046e-06],\n",
       "             [ 3.26417030e-05],\n",
       "             [ 2.97077677e-05],\n",
       "             [-2.24065534e-05],\n",
       "             [ 1.18793578e-05],\n",
       "             [-2.84462294e-06],\n",
       "             [-1.32326732e-05],\n",
       "             [ 1.62037722e-05],\n",
       "             [ 1.85565068e-06],\n",
       "             [ 4.18564632e-05],\n",
       "             [ 6.02732507e-06],\n",
       "             [ 3.73805506e-07],\n",
       "             [-9.41528288e-06],\n",
       "             [ 2.62278045e-05],\n",
       "             [-5.02689363e-06],\n",
       "             [-1.03828243e-05],\n",
       "             [ 1.86528996e-05],\n",
       "             [ 4.73585987e-06],\n",
       "             [ 1.50435642e-06],\n",
       "             [-2.46462077e-05],\n",
       "             [-7.25186474e-05],\n",
       "             [ 1.00518637e-05],\n",
       "             [ 2.35424268e-05],\n",
       "             [ 1.95548728e-06],\n",
       "             [ 3.07835489e-06],\n",
       "             [-1.67111994e-05],\n",
       "             [-2.35614334e-05],\n",
       "             [ 2.65658182e-05],\n",
       "             [-1.13340657e-05],\n",
       "             [ 3.95400093e-06],\n",
       "             [ 6.74568728e-05],\n",
       "             [ 1.69869072e-05],\n",
       "             [ 2.39420460e-05],\n",
       "             [ 6.52252857e-05],\n",
       "             [ 2.73519909e-05],\n",
       "             [-4.11992642e-06],\n",
       "             [ 4.57745045e-06],\n",
       "             [ 4.02943733e-05],\n",
       "             [ 2.56958137e-05],\n",
       "             [-5.80879487e-06],\n",
       "             [-4.66778056e-06],\n",
       "             [-4.43248382e-07],\n",
       "             [-1.90375540e-05],\n",
       "             [-3.44720102e-05],\n",
       "             [ 3.45314106e-06],\n",
       "             [ 5.67002862e-05],\n",
       "             [ 7.70079059e-05],\n",
       "             [ 3.57912395e-05],\n",
       "             [-1.31197758e-05],\n",
       "             [-1.17778945e-05],\n",
       "             [ 3.22971027e-05],\n",
       "             [ 2.23823408e-05],\n",
       "             [-1.38226733e-05],\n",
       "             [ 4.04777638e-05],\n",
       "             [-1.77476904e-05],\n",
       "             [ 1.75615969e-05],\n",
       "             [ 1.55717025e-05],\n",
       "             [ 2.76286719e-05],\n",
       "             [ 3.26813165e-06],\n",
       "             [ 2.33689170e-05],\n",
       "             [-5.53037535e-06],\n",
       "             [ 6.06835374e-06],\n",
       "             [ 3.47209461e-05],\n",
       "             [ 2.74766194e-06],\n",
       "             [-3.24412611e-07],\n",
       "             [-2.38373850e-05],\n",
       "             [ 7.14719044e-06],\n",
       "             [ 4.16892108e-05],\n",
       "             [ 1.61565185e-05],\n",
       "             [ 1.26092937e-05],\n",
       "             [ 9.91705065e-07],\n",
       "             [ 1.61462722e-05],\n",
       "             [ 6.23411597e-06],\n",
       "             [ 1.21005041e-06],\n",
       "             [-3.48482490e-06],\n",
       "             [-6.04978777e-06],\n",
       "             [ 3.74524752e-05],\n",
       "             [ 4.98688642e-05],\n",
       "             [-2.38801167e-05],\n",
       "             [ 3.65167944e-05],\n",
       "             [ 2.16804110e-05],\n",
       "             [ 1.06252210e-05],\n",
       "             [-6.46141234e-06],\n",
       "             [ 1.31094475e-05],\n",
       "             [ 1.67953203e-07],\n",
       "             [ 7.80841219e-06],\n",
       "             [ 7.84313852e-06],\n",
       "             [ 1.77906804e-05],\n",
       "             [ 9.40056725e-06],\n",
       "             [ 3.21918960e-05],\n",
       "             [-1.18416556e-05],\n",
       "             [ 4.08100932e-05],\n",
       "             [ 1.25278473e-06],\n",
       "             [-8.09485527e-08],\n",
       "             [-1.22430993e-06],\n",
       "             [-9.41689905e-06],\n",
       "             [-1.94937202e-05],\n",
       "             [ 7.99687950e-06],\n",
       "             [-1.15080575e-05],\n",
       "             [-1.52974644e-05],\n",
       "             [ 1.19766974e-05],\n",
       "             [ 4.98420195e-06],\n",
       "             [ 9.63314415e-06],\n",
       "             [ 6.13032080e-06],\n",
       "             [-1.39669519e-05]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([1.], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.array([]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_obs = jnp.array([])\n",
    "d_prop = jrandom.uniform(key, shape=(1,), minval=-10., maxval=10.)\n",
    "d_sim = jnp.concatenate((d_obs, d_prop), axis=0)\n",
    "len_x = len(d_sim)\n",
    "len_d = len(d_obs)\n",
    "len_xi = len(d_prop)\n",
    "num_samples = 100\n",
    "\n",
    "# Params and hyperparams\n",
    "theta_shape = (2,)\n",
    "d_shape = (len(d_obs),)\n",
    "xi_shape = (len_xi, )\n",
    "EVENT_SHAPE = (len(d_sim),)\n",
    "# EVENT_DIM is important for the normalizing flow's block.\n",
    "EVENT_DIM = 1\n",
    "cond_info_shape = (theta_shape[0], len_d, len_xi)\n",
    "\n",
    "# Simulating the data to be used to train the flow.\n",
    "num_samples = 10000\n",
    "# TODO: put this function in training since d will be changing.\n",
    "X = sim_data(d_sim, num_samples, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example using a more simple linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2181.5369\n",
      "1858.5502\n",
      "1585.1548\n",
      "1353.422\n",
      "1156.7448\n",
      "989.6083\n",
      "847.4021\n",
      "726.26587\n",
      "622.9615\n",
      "534.76965\n",
      "459.40234\n",
      "394.93176\n",
      "339.73135\n",
      "292.42667\n",
      "251.85446\n",
      "217.0293\n",
      "187.11482\n",
      "161.40063\n",
      "139.28238\n",
      "120.24537\n",
      "103.85087\n",
      "89.72437\n",
      "77.54581\n",
      "67.04163\n",
      "57.97752\n",
      "50.15276\n",
      "43.395264\n",
      "37.557304\n",
      "32.51204\n",
      "28.15043\n",
      "24.378696\n",
      "21.116192\n",
      "18.293394\n",
      "15.850478\n",
      "13.735813\n",
      "11.904947\n",
      "10.31944\n",
      "8.946174\n",
      "7.7565503\n",
      "6.725816\n",
      "5.8326335\n",
      "5.058549\n",
      "4.3875713\n",
      "3.8059084\n",
      "3.3016088\n",
      "2.8643444\n",
      "2.4851553\n",
      "2.156312\n",
      "1.8710963\n",
      "1.6236962\n",
      "1.4090894\n",
      "1.2229112\n",
      "1.0613791\n",
      "0.92123014\n",
      "0.7996186\n",
      "0.6940952\n",
      "0.6025214\n",
      "0.5230455\n",
      "0.45407078\n",
      "0.39420485\n",
      "0.34224513\n",
      "0.29714483\n",
      "0.25799254\n",
      "0.22400692\n",
      "0.19450277\n",
      "0.16889036\n",
      "0.1466547\n",
      "0.12734972\n",
      "0.110588394\n",
      "0.09603701\n",
      "0.08339975\n",
      "0.07242788\n",
      "0.06290057\n",
      "0.054628\n",
      "0.047444887\n",
      "0.041206427\n",
      "0.03578893\n",
      "0.03108498\n",
      "0.026999\n",
      "0.023450699\n",
      "0.020369269\n",
      "0.017693063\n",
      "0.015368364\n",
      "0.01334941\n",
      "0.011596036\n",
      "0.01007299\n",
      "0.008750262\n",
      "0.007601229\n",
      "0.0066029932\n",
      "0.0057360493\n",
      "0.0049831304\n",
      "0.004328905\n",
      "0.0037607104\n",
      "0.0032672042\n",
      "0.0028383692\n",
      "0.0024660188\n",
      "0.002142265\n",
      "0.0018611191\n",
      "0.0016168596\n",
      "0.0014047199\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# create our dataset\n",
    "X, y = make_regression(n_features=3)\n",
    "X, X_test, y, y_test = train_test_split(X, y)\n",
    "\n",
    "\n",
    "# model weights\n",
    "params = {\n",
    "    'w': jnp.zeros(X.shape[1:]),\n",
    "    'b': 0.\n",
    "}\n",
    "\n",
    "\n",
    "def forward(params, X):\n",
    "    return jnp.dot(X, params['w']) + params['b']\n",
    "\n",
    "\n",
    "def loss_fn(params, X, y):\n",
    "    err = forward(params, X) - y\n",
    "    return jnp.mean(jnp.square(err))  # mse\n",
    "\n",
    "\n",
    "grad_fn = jax.grad(loss_fn)\n",
    "grad_xs = jax.grad(loss_fn, argnums=1)\n",
    "\n",
    "\n",
    "def update(params, grads):\n",
    "    return jax.tree_map(lambda p, g: p - 0.05 * g, params, grads)\n",
    "\n",
    "\n",
    "# the main training loop\n",
    "for _ in range(100):\n",
    "    loss = loss_fn(params, X_test, y_test)\n",
    "    print(loss)\n",
    "\n",
    "    grads = grad_fn(params, X, y)\n",
    "    # print(grads)\n",
    "    grads_x = grad_xs(params, X, y)\n",
    "    # print(grads_x)\n",
    "    params = update(params, grads)\n",
    "# jvp = jvp_fn(params, X, y)\n",
    "# vjp_fn, grad_inputs = jvp_fn(params, X, y)\n",
    "# print(grad_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[ 3.52432905e-03,  2.47096978e-02,  5.91810495e-02],\n",
       "             [ 4.47242710e-05,  3.13569850e-04,  7.51016545e-04],\n",
       "             [-1.65014213e-03, -1.15694404e-02, -2.77094282e-02],\n",
       "             [ 2.14535417e-03,  1.50414603e-02,  3.60250995e-02],\n",
       "             [-3.33245192e-03, -2.33644154e-02, -5.59590235e-02],\n",
       "             [-2.63125426e-03, -1.84481926e-02, -4.41844091e-02],\n",
       "             [-4.31130687e-03, -3.02273389e-02, -7.23960921e-02],\n",
       "             [-1.45995826e-03, -1.02360277e-02, -2.45158337e-02],\n",
       "             [-6.79470249e-04, -4.76388726e-03, -1.14097642e-02],\n",
       "             [-1.30786747e-03, -9.16969217e-03, -2.19619032e-02],\n",
       "             [-2.38773972e-03, -1.67408697e-02, -4.00952771e-02],\n",
       "             [ 5.24106342e-03,  3.67460325e-02,  8.80087093e-02],\n",
       "             [-1.81098015e-03, -1.26971044e-02, -3.04102451e-02],\n",
       "             [-7.59501301e-04, -5.32499887e-03, -1.27536571e-02],\n",
       "             [ 2.56988191e-04,  1.80178997e-03,  4.31538327e-03],\n",
       "             [ 1.57931703e-03,  1.10728731e-02,  2.65201237e-02],\n",
       "             [-1.80999271e-03, -1.26901809e-02, -3.03936619e-02],\n",
       "             [ 2.51245988e-03,  1.76153034e-02,  4.21895944e-02],\n",
       "             [ 2.02719448e-03,  1.42130218e-02,  3.40409465e-02],\n",
       "             [ 9.46122920e-04,  6.63343631e-03,  1.58874355e-02],\n",
       "             [-1.07267709e-03, -7.52073014e-03, -1.80125497e-02],\n",
       "             [ 3.48426029e-03,  2.44287699e-02,  5.85082099e-02],\n",
       "             [ 7.25746504e-04,  5.08833816e-03,  1.21868420e-02],\n",
       "             [ 2.06126671e-04,  1.44519086e-03,  3.46130924e-03],\n",
       "             [ 2.18965521e-04,  1.53520633e-03,  3.67690111e-03],\n",
       "             [-4.19787364e-03, -2.94320397e-02, -7.04913065e-02],\n",
       "             [-2.66031804e-03, -1.86519641e-02, -4.46724519e-02],\n",
       "             [ 2.23141653e-03,  1.56448595e-02,  3.74702737e-02],\n",
       "             [ 2.80422578e-03,  1.96609274e-02,  4.70889695e-02],\n",
       "             [-3.16794566e-03, -2.22110320e-02, -5.31966090e-02],\n",
       "             [ 3.18854419e-03,  2.23554522e-02,  5.35425022e-02],\n",
       "             [ 1.41096604e-03,  9.89253446e-03,  2.36931499e-02],\n",
       "             [ 7.20808515e-04,  5.05371718e-03,  1.21039227e-02],\n",
       "             [ 2.03728225e-04,  1.42837490e-03,  3.42103420e-03],\n",
       "             [ 8.99907536e-05,  6.30941242e-04,  1.51113793e-03],\n",
       "             [-1.74523419e-04, -1.22361479e-03, -2.93062278e-03],\n",
       "             [ 5.09038335e-04,  3.56895872e-03,  8.54784716e-03],\n",
       "             [ 1.14561850e-03,  8.03213567e-03,  1.92373954e-02],\n",
       "             [ 4.67276899e-04,  3.27616162e-03,  7.84658268e-03],\n",
       "             [-1.44345104e-03, -1.01202922e-02, -2.42386423e-02],\n",
       "             [ 7.13613117e-04,  5.00326883e-03,  1.19830966e-02],\n",
       "             [-9.46687185e-04, -6.63739257e-03, -1.58969108e-02],\n",
       "             [ 1.18371169e-03,  8.29921383e-03,  1.98770612e-02],\n",
       "             [-2.06169020e-03, -1.44548770e-02, -3.46202031e-02],\n",
       "             [ 1.16367755e-03,  8.15875083e-03,  1.95406433e-02],\n",
       "             [-2.83413590e-03, -1.98706333e-02, -4.75912280e-02],\n",
       "             [ 2.29067286e-03,  1.60603151e-02,  3.84653136e-02],\n",
       "             [-1.37615297e-03, -9.64845438e-03, -2.31085625e-02],\n",
       "             [ 4.23991727e-03,  2.97268145e-02,  7.11973086e-02],\n",
       "             [ 1.37304922e-03,  9.62669309e-03,  2.30564438e-02],\n",
       "             [-1.34426763e-03, -9.42489970e-03, -2.25731395e-02],\n",
       "             [ 7.69059872e-04,  5.39201591e-03,  1.29141668e-02],\n",
       "             [-3.39114363e-03, -2.37759128e-02, -5.69445826e-02],\n",
       "             [-1.63165983e-04, -1.14398578e-03, -2.73990724e-03],\n",
       "             [ 1.40521675e-03,  9.85222589e-03,  2.35966071e-02],\n",
       "             [ 2.41807336e-03,  1.69535428e-02,  4.06046435e-02],\n",
       "             [-6.39754580e-04, -4.48543346e-03, -1.07428534e-02],\n",
       "             [-1.07115156e-04, -7.51003448e-04, -1.79869344e-03],\n",
       "             [ 4.32287547e-04,  3.03084520e-03,  7.25903595e-03],\n",
       "             [ 4.29367088e-03,  3.01036928e-02,  7.20999539e-02],\n",
       "             [ 1.97802612e-04,  1.38682942e-03,  3.32153053e-03],\n",
       "             [ 2.66539725e-03,  1.86875742e-02,  4.47577424e-02],\n",
       "             [ 7.00209930e-04,  4.90929652e-03,  1.17580276e-02],\n",
       "             [ 3.15835187e-03,  2.21437681e-02,  5.30355051e-02],\n",
       "             [-1.02047517e-03, -7.15473387e-03, -1.71359703e-02],\n",
       "             [-2.39281901e-04, -1.67764805e-03, -4.01805667e-03],\n",
       "             [-9.49367823e-04, -6.65618712e-03, -1.59419235e-02],\n",
       "             [-1.43089448e-03, -1.00322561e-02, -2.40277890e-02],\n",
       "             [-5.30031975e-03, -3.71614881e-02, -8.90037492e-02],\n",
       "             [ 1.88603799e-03,  1.32233482e-02,  3.16706263e-02],\n",
       "             [-2.65573291e-03, -1.86198168e-02, -4.45954539e-02],\n",
       "             [ 2.11629026e-06,  1.48376885e-05,  3.55370576e-05],\n",
       "             [-1.43089448e-03, -1.00322561e-02, -2.40277890e-02],\n",
       "             [ 3.64679168e-03,  2.55683064e-02,  6.12374619e-02],\n",
       "             [-2.53221183e-03, -1.77537892e-02, -4.25212756e-02]],            dtype=float32)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0\n"
     ]
    }
   ],
   "source": [
    "print(jnp.min(grads_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 3)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 3)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 3)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Using a non-tuple sequence for multidimensional indexing is not allowed; use `arr[tuple(seq)]` instead of `arr[seq]`. See https://github.com/google/jax/issues/4564 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [58], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m forward_grads_X \u001b[39m=\u001b[39m forward_grad(params, X)\n\u001b[1;32m      6\u001b[0m \u001b[39m# Compute the Jacobian of the loss function with respect to X using the chain rule\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m loss_grads_X \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39mdot(grad_fn(params[\u001b[39m'\u001b[39;49m\u001b[39mw\u001b[39;49m\u001b[39m'\u001b[39;49m], X, y), forward_grads_X)\n",
      "    \u001b[0;31m[... skipping hidden 10 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn [57], line 24\u001b[0m, in \u001b[0;36mloss_fn\u001b[0;34m(params, X, y)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloss_fn\u001b[39m(params, X, y):\n\u001b[0;32m---> 24\u001b[0m     err \u001b[39m=\u001b[39m forward(params, X) \u001b[39m-\u001b[39m y\n\u001b[1;32m     25\u001b[0m     \u001b[39mreturn\u001b[39;00m jnp\u001b[39m.\u001b[39mmean(jnp\u001b[39m.\u001b[39msquare(err))\n",
      "Cell \u001b[0;32mIn [57], line 20\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(params, X)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(params, X):\n\u001b[0;32m---> 20\u001b[0m     \u001b[39mreturn\u001b[39;00m jnp\u001b[39m.\u001b[39mdot(X, params[\u001b[39m'\u001b[39;49m\u001b[39mw\u001b[39;49m\u001b[39m'\u001b[39;49m]) \u001b[39m+\u001b[39m params[\u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m]\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/sdm3/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py:3649\u001b[0m, in \u001b[0;36m_rewriting_take\u001b[0;34m(arr, idx, indices_are_sorted, unique_indices, mode, fill_value)\u001b[0m\n\u001b[1;32m   3643\u001b[0m     \u001b[39mif\u001b[39;00m (\u001b[39misinstance\u001b[39m(aval, core\u001b[39m.\u001b[39mDShapedArray) \u001b[39mand\u001b[39;00m aval\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m () \u001b[39mand\u001b[39;00m\n\u001b[1;32m   3644\u001b[0m         dtypes\u001b[39m.\u001b[39missubdtype(aval\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39minteger) \u001b[39mand\u001b[39;00m\n\u001b[1;32m   3645\u001b[0m         \u001b[39mnot\u001b[39;00m dtypes\u001b[39m.\u001b[39missubdtype(aval\u001b[39m.\u001b[39mdtype, dtypes\u001b[39m.\u001b[39mbool_) \u001b[39mand\u001b[39;00m\n\u001b[1;32m   3646\u001b[0m         \u001b[39misinstance\u001b[39m(arr\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39mint\u001b[39m)):\n\u001b[1;32m   3647\u001b[0m       \u001b[39mreturn\u001b[39;00m lax\u001b[39m.\u001b[39mdynamic_index_in_dim(arr, idx, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m-> 3649\u001b[0m treedef, static_idx, dynamic_idx \u001b[39m=\u001b[39m _split_index_for_jit(idx, arr\u001b[39m.\u001b[39;49mshape)\n\u001b[1;32m   3650\u001b[0m \u001b[39mreturn\u001b[39;00m _gather(arr, treedef, static_idx, dynamic_idx, indices_are_sorted,\n\u001b[1;32m   3651\u001b[0m                unique_indices, mode, fill_value)\n",
      "File \u001b[0;32m~/anaconda3/envs/sdm3/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py:3724\u001b[0m, in \u001b[0;36m_split_index_for_jit\u001b[0;34m(idx, shape)\u001b[0m\n\u001b[1;32m   3719\u001b[0m \u001b[39m\"\"\"Splits indices into necessarily-static and dynamic parts.\u001b[39;00m\n\u001b[1;32m   3720\u001b[0m \n\u001b[1;32m   3721\u001b[0m \u001b[39mUsed to pass indices into `jit`-ted function.\u001b[39;00m\n\u001b[1;32m   3722\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3723\u001b[0m \u001b[39m# Convert list indices to tuples in cases (deprecated by NumPy.)\u001b[39;00m\n\u001b[0;32m-> 3724\u001b[0m idx \u001b[39m=\u001b[39m _eliminate_deprecated_list_indexing(idx)\n\u001b[1;32m   3726\u001b[0m \u001b[39m# Expand any (concrete) boolean indices. We can then use advanced integer\u001b[39;00m\n\u001b[1;32m   3727\u001b[0m \u001b[39m# indexing logic to handle them.\u001b[39;00m\n\u001b[1;32m   3728\u001b[0m idx \u001b[39m=\u001b[39m _expand_bool_indices(idx, shape)\n",
      "File \u001b[0;32m~/anaconda3/envs/sdm3/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py:4004\u001b[0m, in \u001b[0;36m_eliminate_deprecated_list_indexing\u001b[0;34m(idx)\u001b[0m\n\u001b[1;32m   4000\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   4001\u001b[0m     msg \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mUsing a non-tuple sequence for multidimensional indexing is not allowed; \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4002\u001b[0m            \u001b[39m\"\u001b[39m\u001b[39muse `arr[array(seq)]` instead of `arr[seq]`. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4003\u001b[0m            \u001b[39m\"\u001b[39m\u001b[39mSee https://github.com/google/jax/issues/4564 for more information.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 4004\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[1;32m   4005\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   4006\u001b[0m   idx \u001b[39m=\u001b[39m (idx,)\n",
      "\u001b[0;31mTypeError\u001b[0m: Using a non-tuple sequence for multidimensional indexing is not allowed; use `arr[tuple(seq)]` instead of `arr[seq]`. See https://github.com/google/jax/issues/4564 for more information."
     ]
    }
   ],
   "source": [
    "forward_grad = jax.jacfwd(forward)\n",
    "\n",
    "# Compute the gradients of the forward pass with respect to X\n",
    "forward_grads_X = forward_grad(params, X)\n",
    "\n",
    "# Compute the Jacobian of the loss function with respect to X using the chain rule\n",
    "loss_grads_X = jnp.dot(grad_fn(params['w'], X, y), forward_grads_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('sdm3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "32bac022e209f3f8f811ac02bf6d6b971751e1ab224096f1893a92a620959b98"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
