{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Iterator, Mapping, Optional, Sequence, Tuple, Callable, Union\n",
    "\n",
    "import distrax\n",
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import optax\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from lfiax.flows.nsf import make_nsf\n",
    "\n",
    "Array = jnp.ndarray\n",
    "PRNGKey = Array\n",
    "Batch = Mapping[str, np.ndarray]\n",
    "OptState = Any\n",
    "\n",
    "\n",
    "# ----------------------------------------\n",
    "# Helper functions to load and process data\n",
    "# ----------------------------------------\n",
    "def load_dataset(split: tfds.Split, batch_size: int) -> Iterator[Batch]:\n",
    "  ds = tfds.load(\"mnist\", split=split, shuffle_files=True)\n",
    "  # ds = split\n",
    "  ds = ds.shuffle(buffer_size=10 * batch_size)\n",
    "  ds = ds.batch(batch_size)\n",
    "  ds = ds.prefetch(buffer_size=1000)\n",
    "  ds = ds.repeat()\n",
    "  return iter(tfds.as_numpy(ds))\n",
    "\n",
    "\n",
    "def one_hot_mnist(x, dtype=jnp.float32):\n",
    "  \"\"\"Create a one-hot encoding of x of size 10 for MNIST.\"\"\"\n",
    "  return jnp.array(x[:, None] == jnp.arange(10), dtype)\n",
    "\n",
    "\n",
    "def prepare_data(batch: Batch, prng_key: Optional[PRNGKey] = None) -> Array:\n",
    "  data = batch[\"image\"].astype(np.float32)\n",
    "  label = batch[\"label\"].astype(np.float32)\n",
    "  label = one_hot_mnist(label)\n",
    "  label = jnp.expand_dims(label, -1)\n",
    "  if prng_key is not None:\n",
    "    # Dequantize pixel values {0, 1, ..., 255} with uniform noise [0, 1).\n",
    "    data += jax.random.uniform(prng_key, data.shape)\n",
    "  return data / 256., label  # Normalize pixel values from [0, 256) to [0, 1).\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Haiku transform functions for training and evaluation\n",
    "# ----------------------------\n",
    "@hk.without_apply_rng\n",
    "@hk.transform\n",
    "def log_prob(data: Array, cond_data: Array) -> Array:\n",
    "  model = make_nsf(\n",
    "      event_shape=MNIST_IMAGE_SHAPE,\n",
    "      cond_info_shape=cond_info_shape,\n",
    "      num_layers=flow_num_layers,\n",
    "      hidden_sizes=[hidden_size] * mlp_num_layers,\n",
    "      num_bins=num_bins,\n",
    "      standardize=False,\n",
    "      base_dist='uniform',\n",
    "      )\n",
    "  return model.log_prob(data, cond_data)\n",
    "\n",
    "@hk.without_apply_rng\n",
    "@hk.transform\n",
    "def model_sample(key: PRNGKey, num_samples: int, cond_data: Array) -> Array:\n",
    "  model = make_nsf(\n",
    "      event_shape=MNIST_IMAGE_SHAPE,\n",
    "      cond_info_shape=cond_info_shape,\n",
    "      num_layers=flow_num_layers,\n",
    "      hidden_sizes=[hidden_size] * mlp_num_layers,\n",
    "      num_bins=num_bins,\n",
    "      standardize=False,\n",
    "      base_dist='uniform',\n",
    "      )\n",
    "  z = jnp.repeat(cond_data, num_samples, axis=0)\n",
    "  z = jnp.expand_dims(z, -1)\n",
    "  return model._sample_n(key=key, \n",
    "                         n=[num_samples],\n",
    "                         z=z)\n",
    "\n",
    "def loss_fn(params: hk.Params, prng_key: PRNGKey, batch: Batch) -> Array:\n",
    "  data = prepare_data(batch, prng_key)\n",
    "  # Loss is average negative log likelihood.\n",
    "  loss = -jnp.mean(log_prob.apply(params, data[0], data[1]))\n",
    "  return loss\n",
    "\n",
    "@jax.jit\n",
    "def eval_fn(params: hk.Params, batch: Batch) -> Array:\n",
    "  data = prepare_data(batch)  # We don't dequantize during evaluation.\n",
    "  loss = -jnp.mean(log_prob.apply(params, data[0], data[1]))\n",
    "  return loss\n",
    "\n",
    "@jax.jit\n",
    "def update(params: hk.Params,\n",
    "            prng_key: PRNGKey,\n",
    "            opt_state: OptState,\n",
    "            batch: Batch) -> Tuple[hk.Params, OptState]:\n",
    "  \"\"\"Single SGD update step.\"\"\"\n",
    "  grads = jax.grad(loss_fn)(params, prng_key, batch)\n",
    "  updates, new_opt_state = optimizer.update(grads, opt_state)\n",
    "  new_params = optax.apply_updates(params, updates)\n",
    "  return new_params, new_opt_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:     0; Validation loss: -2.849\n"
     ]
    }
   ],
   "source": [
    "MNIST_IMAGE_SHAPE = (28, 28, 1)\n",
    "cond_info_shape = (10,1)\n",
    "batch_size = 128\n",
    "\n",
    "flow_num_layers = 10\n",
    "mlp_num_layers = 4\n",
    "hidden_size = 500\n",
    "num_bins = 4\n",
    "learning_rate = 1e-4\n",
    "\n",
    "training_steps =  1#000\n",
    "eval_frequency =  100\n",
    "\n",
    "optimizer = optax.adam(learning_rate)\n",
    "\n",
    "# Training\n",
    "prng_seq = hk.PRNGSequence(42)\n",
    "params = log_prob.init(next(prng_seq), \n",
    "                    np.zeros((1, *MNIST_IMAGE_SHAPE)), \n",
    "                    np.zeros((1, *cond_info_shape)))\n",
    "opt_state = optimizer.init(params)\n",
    "\n",
    "train_ds = load_dataset(tfds.Split.TRAIN, batch_size)\n",
    "valid_ds = load_dataset(tfds.Split.TEST, batch_size)\n",
    "\n",
    "for step in range(training_steps):\n",
    "  params, opt_state = update(params, next(prng_seq), opt_state,\n",
    "                              next(train_ds))\n",
    "\n",
    "  if step % eval_frequency == 0:\n",
    "    val_loss = eval_fn(params, next(valid_ds))\n",
    "    print(f\"STEP: {step:5d}; Validation loss: {val_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(MNIST_IMAGE_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('sdm3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "32bac022e209f3f8f811ac02bf6d6b971751e1ab224096f1893a92a620959b98"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
